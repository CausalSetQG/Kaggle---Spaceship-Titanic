{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to generate a large number of fake three letter words which sound like they could be real words. We will do this using the CMU of phonetic words and a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8242\n",
      "960\n",
      "['saa', 'aud', 'ouu', 'aam', 'pih', 'mox', 'ioe', 'buo', 'ioy', 'coe', 'fep', 'aer', 'oap', 'oip', 'eow', 'iaw', 'uar', 'aat', 'iud', 'eiy', 'aik', 'aot', 'iep', 'oou', 'aui', 'uon', 'fai', 'pai', 'woy', 'aar', 'tob', 'rer', 'kua', 'kee', 'iek', 'ooz', 'fiy', 'loa', 'uew', 'vao', 'gia', 'yoo', 'uoy', 'eec', 'tib', 'fuy', 'hiy', 'mah', 'iag', 'oae', 'aop', 'dem', 'tue', 'eiu', 'oiv', 'ara', 'eue', 'ouo', 'eiv', 'arz', 'hio', 'kot', 'ooy', 'toi', 'jao', 'uom', 'uou', 'aog', 'doa', 'mex', 'eal', 'iug', 'ieo', 'ior', 'ael', 'yoe', 'eac', 'uea', 'eia', 'rio', 'iuy', 'uii', 'aie', 'aek', 'lon', 'oug', 'oac', 'aur', 'oiw', 'ioo', 'eog', 'aea', 'eun', 'arn', 'teh', 'uem', 'iok', 'uac', 'uek', 'geb', 'cet', 'eof', 'aug', 'uot', 'ceo', 'oad', 'luy', 'cuo', 'gom', 'ead', 'pem', 'euh', 'aab', 'iar', 'zaa', 'lue', 'aib', 'euz', 'euu', 'yeg', 'iob', 'euf', 'eus', 'nop', 'kuo', 'eur', 'aes', 'auz', 'uog', 'ruo', 'uum', 'aaq', 'aoc', 'oii', 'iip', 'uee', 'wao', 'oay', 'tud', 'jes', 'yot', 'cae', 'uuo', 'lao', 'sek', 'yey', 'tal', 'vio', 'uiy', 'kus', 'eis', 'oaa', 'cen', 'aep', 'cus', 'oei', 'aeo', 'sii', 'iim', 'kaa', 'sio', 'aee', 'oel', 'eug', 'iah', 'iii', 'oaw', 'der', 'aob', 'oed', 'yue', 'yoa', 'joo', 'jea', 'aeb', 'pio', 'cao', 'rea', 'eez', 'dao', 'gaa', 'uod', 'ueo', 'uik', 'oux', 'uec', 'sak', 'gea', 'sie', 'aax', 'keo', 'jua', 'fam', 'uao', 'riy', 'meb', 'teu', 'aon', 'hia', 'pey', 'ceg', 'iui', 'eeb', 'auh', 'iue', 'aro', 'yed', 'uus', 'ial', 'oea', 'vaa', 'uie', 'ges', 'aoz', 'aix', 'ris', 'boe', 'iul', 'uaw', 'uoi', 'oui', 'sas', 'oas', 'aed', 'sep', 'sih', 'aiv', 'vos', 'iey', 'ioh', 'oov', 'uuk', 'neo', 'aip', 'eaz', 'pae', 'ueg', 'giy', 'ooo', 'uei', 'oai', 'piw', 'puw', 'mio', 'eax', 'zia', 'oec', 'guo', 'iuo', 'uoe', 'iew', 'yia', 'iiu', 'oax', 'pue', 'uid', 'uoh', 'euc', 'mey', 'gog', 'sor', 'mit', 'aau', 'eaf', 'aut', 'iut', 'aeu', 'sia', 'seh', 'oob', 'iaa', 'jeo', 'jis', 'eok', 'peo', 'oul', 'ued', 'ced', 'fos', 'arw', 'aio', 'wie', 'uiz', 'auy', 'wes', 'oiu', 'eim', 'feo', 'yis', 'yos', 'nar', 'mie', 'mab', 'piy', 'eio', 'nuo', 'uen', 'oav', 'uag', 'cea', 'uap', 'eoy', 'eeo', 'iit', 'oer', 'lut', 'ooe', 'uiu', 'aew', 'auq', 'eod', 'ayo', 'peb', 'oum', 'aux', 'ood', 'uab', 'baw', 'uio', 'aaa', 'lan', 'uob', 'uux', 'haa', 'iig', 'jue', 'euo', 'dea', 'uos', 'vea', 'aii', 'eum', 'wio', 'ruy', 'oox', 'lus', 'uay', 'zae', 'woa', 'zoe', 'eao', 'aei', 'mip', 'oek', 'tua', 'iom', 'niy', 'com', 'aef', 'moh', 'eak', 'iax', 'mue', 'oab', 'roa', 'uir', 'bem', 'uan', 'uug', 'eob', 'iel', 'iid', 'oin', 'uic', 'uup', 'suy', 'bue', 'hus', 'eoi', 'eef', 'mer', 'naa', 'oam', 'iau', 'teo', 'euy', 'aaz', 'aol', 'fea', 'mub', 'fut', 'eer', 'dai', 'arx', 'pid', 'ces', 'uaa', 'pim', 'jat', 'ahe', 'nen', 'aae', 'coa', 'eoo', 'wia', 'aeg', 'oee', 'oaz', 'eib', 'kie', 'ees', 'waa', 'tep', 'aif', 'bax', 'iab', 'gah', 'uix', 'vus', 'rua', 'wua', 'nia', 'deo', 'aan', 'oey', 'yuo', 'iia', 'dat', 'iib', 'oeg', 'eeh', 'aos', 'uox', 'aup', 'eox', 'noe', 'ooa', 'daa', 'oia', 'ney', 'fot', 'cem', 'ook', 'leb', 'aec', 'har', 'duy', 'iis', 'iow', 'ooi', 'eig', 'uak', 'ooc', 'eif', 'feb', 'bom', 'iub', 'noa', 'aiu', 'iex', 'iat', 'diy', 'seo', 'oeo', 'iee', 'tey', 'juo', 'pab', 'uis', 'koy', 'aiz', 'oib', 'auu', 'uuy', 'iup', 'wue', 'uih', 'auj', 'ues', 'ouh', 'tuo', 'dua', 'eud', 'pou', 'ies', 'ros', 'sil', 'uui', 'aoh', 'tah', 'aej', 'suo', 'lua', 'eoe', 'nes', 'fua', 'oif', 'eiw', 'auv', 'rop', 'foa', 'gua', 'iuu', 'cie', 'eom', 'hab', 'kao', 'uae', 'eet', 'yog', 'sem', 'arl', 'uax', 'oim', 'siw', 'rae', 'beo', 'iem', 'aao', 'eoh', 'oie', 'zao', 'eeu', 'pog', 'uuu', 'soe', 'eih', 'jaa', 'aus', 'suh', 'kia', 'joa', 'bau', 'kap', 'jae', 'iih', 'uuc', 'aub', 'auo', 'uib', 'rey', 'oew', 'dio', 'yaa', 'bea', 'auw', 'arg', 'uun', 'uop', 'oan', 'uur', 'oau', 'aiw', 'oep', 'aak', 'muo', 'mea', 'eic', 'tur', 'seu', 'wam', 'yio', 'dar', 'fuo', 'ool', 'euw', 'aru', 'ouv', 'lia', 'eev', 'eip', 'oeh', 'vue', 'eua', 'uil', 'fis', 'pex', 'iot', 'meo', 'oah', 'suu', 'aoy', 'dut', 'oua', 'aoq', 'oag', 'eir', 'mau', 'aod', 'rie', 'ioi', 'uex', 'sah', 'aij', 'iio', 'ias', 'jos', 'jia', 'huy', 'ien', 'mep', 'paa', 'ual', 'uaz', 'deh', 'gao', 'koo', 'hee', 'soa', 'iil', 'eie', 'aez', 'ium', 'uez', 'rao', 'kio', 'voa', 'oid', 'aap', 'cia', 'aex', 'bep', 'eey', 'iua', 'oub', 'iai', 'aof', 'iet', 'oem', 'pob', 'aac', 'aem', 'cio', 'yat', 'ter', 'uor', 'iin', 'eab', 'aey', 'poy', 'oeu', 'iuw', 'uuz', 'aeq', 'sid', 'iay', 'uep', 'oiy', 'eeg', 'iea', 'ieh', 'aig', 'oen', 'ouy', 'lom', 'pua', 'oic', 'uut', 'tir', 'oio', 'sok', 'tem', 'ian', 'uul', 'iad', 'aoo', 'eiz', 'heo', 'det', 'aya', 'rog', 'jie', 'eae', 'beb', 'fod', 'arr', 'ieb', 'aav', 'rar', 'muy', 'nao', 'uok', 'uas', 'eov', 'uai', 'aoe', 'dax', 'eid', 'suw', 'tuy', 'iuk', 'ouw', 'eam', 'tol', 'iog', 'uam', 'sao', 'oog', 'iap', 'eut', 'loe', 'lio', 'uua', 'ses', 'wuo', 'tox', 'aaw', 'uat', 'ieu', 'seb', 'nue', 'fue', 'aiy', 'eep', 'fao', 'iix', 'arp', 'jas', 'eos', 'iak', 'eil', 'aad', 'aag', 'dia', 'bup', 'ves', 'aet', 'aaj', 'aih', 'aic', 'ioa', 'iiy', 'tus', 'aox', 'uer', 'mia', 'tia', 'uoz', 'soo', 'pum', 'bai', 'bim', 'por', 'aai', 'mup', 'aaf', 'tou', 'eai', 'ror', 'eaw', 'aou', 'siy', 'mao', 'oao', 'arh', 'fom', 'uel', 'kan', 'uow', 'sut', 'pag', 'cua', 'cuy', 'eou', 'oit', 'kad', 'gep', 'ouz', 'ouf', 'zue', 'zis', 'iao', 'ouc', 'iox', 'pau', 'uig', 'eul', 'uia', 'raa', 'eem', 'sua', 'eaa', 'oun', 'eoc', 'oal', 'weo', 'lae', 'tiy', 'uet', 'uim', 'iol', 'des', 'roy', 'tio', 'ier', 'eee', 'taa', 'nea', 'yua', 'zes', 'uud', 'veo', 'aov', 'uau', 'yiy', 'uuw', 'eei', 'oir', 'uad', 'oiz', 'ein', 'voo', 'zua', 'aoi', 'iop', 'eii', 'gop', 'eup', 'aum', 'jio', 'sul', 'eag', 'miy', 'tos', 'eex', 'eol', 'yee', 'eub', 'ari', 'peu', 'bie', 'yie', 'bia', 'ciy', 'iur', 'zus', 'nad', 'oig', 'teb', 'iou', 'dus', 'rab', 'yoy', 'ueh', 'pib', 'huo', 'iie', 'iun', 'uue', 'oow', 'oev', 'nua', 'aun', 'uin', 'aoa', 'oih', 'bip', 'ieg', 'bua', 'hed', 'uub', 'gax', 'fio', 'toh', 'aul', 'eop', 'uuh', 'mua', 'siu', 'ueb', 'aor', 'soi', 'oix', 'iuh', 'yan', 'oex', 'pao', 'eea', 'aen', 'aay', 'wea', 'iod', 'hea', 'oef', 'nio', 'biy', 'uiw', 'uah', 'aiq', 'heg', 'ius', 'len', 'iam', 'hua', 'ded', 'min', 'vuo', 'eot', 'iae', 'eed', 'eah', 'eay', 'uip', 'eux', 'yab', 'oez', 'eui', 'cey', 'euv', 'toa', 'eoa', 'yeo', 'eix', 'liy', 'oet', 'pei', 'yop', 'aeh', 'iir', 'uol', 'aok', 'oue', 'sux', 'aoj', 'laa', 'iux', 'aev', 'yao', 'kes', 'eoz', 'rus', 'cas', 'rau', 'tei', 'bab', 'luo', 'mai', 'dau', 'auc', 'ueu', 'lem', 'uoa', 'pon', 'tim', 'ber', 'eor', 'poe', 'aow', 'fia', 'vua', 'eit', 'uoc', 'geg', 'kag', 'puo', 'eap', 'iei', 'iik', 'iiw', 'leo', 'aom', 'oeb', 'uoo', 'zie', 'koe', 'ied', 'uit', 'eav', 'ron', 'fus']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "\n",
    "# Open list of scrabble words\n",
    "with open(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\3 Letter Words\\\\Collins Scrabble Words (2019).txt\", 'r') as file:\n",
    "    scrabble_words = file.read().splitlines()\n",
    "\n",
    "# Convert to DataFrame and preprocess\n",
    "df = pd.DataFrame(scrabble_words, columns=['Word'])\n",
    "df = df[df['Word'].str.len() == 3]\n",
    "df['Word'] = df['Word'].str.lower()\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "real_words = df['Word'].tolist()\n",
    "\n",
    "# One-hot encode the real words\n",
    "alphabet = list('abcdefghijklmnopqrstuvwxyz')\n",
    "encoder = OneHotEncoder(categories=[alphabet]*3)\n",
    "X = np.array([list(word) for word in real_words])\n",
    "X_encoded = encoder.fit_transform(X).toarray()\n",
    "\n",
    "# Train a One-Class SVM\n",
    "svm = OneClassSVM(kernel='linear')\n",
    "svm.fit(X_encoded)\n",
    "\n",
    "# Potential Plausible Words must be 3 letters long, not in the list of real words, and contain at least one vowel\n",
    "from itertools import product\n",
    "\n",
    "# Define vowels and consonants\n",
    "vowels = 'aeiouy'\n",
    "consonants = 'bcdfghjklmnpqrstvwxz'\n",
    "\n",
    "# Generate all possible 3-letter combinations with at least one vowel\n",
    "potential_words = set()\n",
    "for i in range(3):  # Position of the vowel\n",
    "    for letters in product(*[vowels if position == i else consonants+vowels for position in range(3)]):\n",
    "        potential_words.add(''.join(letters))\n",
    "potential_words = list(potential_words.difference(set(real_words)))\n",
    "# Encode the random words\n",
    "X_test = np.array([list(word) for word in potential_words])\n",
    "X_test_encoded = encoder.transform(X_test).toarray()\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm.predict(X_test_encoded)\n",
    "\n",
    "# Find words that are predicted as similar to real words\n",
    "predicted_as_real = [word for word, pred in zip(potential_words, y_pred) if pred == 1]\n",
    "\n",
    "print(len(predicted_as_real))\n",
    "print(predicted_as_real)\n",
    "\n",
    "with open('C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\3 Letter Words\\\\predicted_as_real.txt', 'w') as file:\n",
    "    for word in predicted_as_real:\n",
    "        file.write(word + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
