{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "train = pd.read_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Process\\\\CombinedTrain.csv\")\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Process\\\\CombinedTest.csv\")\n",
    "\n",
    "# Separate ID before training\n",
    "train_passenger_ids = train['PassengerId']\n",
    "test_passenger_ids = test['PassengerId']\n",
    "\n",
    "# Prepare data\n",
    "X_train = train.drop(['Transported', 'PassengerId'], axis=1)\n",
    "y_train = train['Transported'].astype('int')  # Convert True/False to 1/0\n",
    "X_test = test.drop('PassengerId', axis=1)\n",
    "\n",
    "# Create the Logistic Regression model with best parameters\n",
    "best_params_lr = {'solver': 'saga', 'penalty': 'l1', 'max_iter': 300, 'l1_ratio': 0.75, 'C': 0.1}\n",
    "lr_model = LogisticRegression(**best_params_lr, random_state=1)\n",
    "\n",
    "# Create the Random Forest model with best parameters\n",
    "best_params_rf = {'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'bootstrap': True}\n",
    "rf_model = RandomForestClassifier(**best_params_rf, random_state=1)\n",
    "\n",
    "# Create the Support Vector Machine model - untuned\n",
    "svm_model = SVC(probability=True, random_state=1)\n",
    "\n",
    "# Create the XGBoost model with best parameters\n",
    "best_params_cv = {'subsample': 0.7, 'reg_lambda': 1.1, 'reg_alpha': 0.1, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
    "xgb_model = xgb.XGBClassifier(**best_params_cv, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    ('lr', lr_model),  # Logistic Regression\n",
    "    ('rf', rf_model),  # Random Forest\n",
    "    ('xgb', xgb_model),  # XGBoost\n",
    "    ('svc', svm_model)  # Support Vector Classifier\n",
    "]\n",
    "\n",
    "# Meta-learner\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_learner)\n",
    "\n",
    "# Fit the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the stacking classifier\n",
    "stacked_predictions = stacking_clf.predict(X_test)\n",
    "\n",
    "# Prepare submission\n",
    "test_passenger_ids = test['PassengerId']\n",
    "test_predictions = pd.DataFrame({\n",
    "    'PassengerId': test_passenger_ids,\n",
    "    'Transported': stacked_predictions\n",
    "})\n",
    "test_predictions['Transported'] = test_predictions['Transported'].astype(bool)\n",
    "\n",
    "# Export to CSV\n",
    "test_predictions.to_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Test\\\\Submission - Stacking.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
