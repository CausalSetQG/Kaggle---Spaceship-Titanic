{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "train = pd.read_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Process\\\\CombinedTrain.csv\")\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Process\\\\CombinedTest.csv\")\n",
    "\n",
    "# Separate ID before training\n",
    "train_passenger_ids = train['PassengerId']\n",
    "test_passenger_ids = test['PassengerId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "490 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "490 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\joshn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.80076211        nan 0.79777037 0.78971785 0.78063058        nan\n",
      " 0.79938142 0.79662028 0.79570054 0.78925675 0.77740861        nan\n",
      " 0.79685056 0.79938161 0.79155831 0.79086892 0.79236364 0.80122202\n",
      " 0.79846128 0.79846188        nan 0.7982312  0.79293915 0.80030188\n",
      " 0.80133729        nan 0.77349812 0.79489528 0.80168205 0.77867444\n",
      " 0.77361339        nan        nan 0.79259359 0.78776276 0.79478008\n",
      " 0.80007127 0.77614372 0.79351478 0.79846102        nan 0.79673569\n",
      " 0.7859215  0.79754048 0.7974262  0.79926707 0.78523198 0.78730273\n",
      " 0.80007173 0.8005321  0.80076231 0.78948836 0.79397462 0.79500957\n",
      " 0.80018687 0.79903718 0.80133742 0.78615291 0.7855776  0.79938148\n",
      " 0.7923643  0.79972697 0.79880624 0.7982308  0.79224823 0.80041722\n",
      "        nan        nan 0.79190407 0.7893715  0.7873028         nan\n",
      "        nan 0.78419518 0.80053216 0.79167372 0.79800131 0.79765529\n",
      "        nan 0.79132869 0.80064724 0.77326863 0.79247977 0.792709\n",
      " 0.79029322 0.79443419 0.7969665  0.79984178        nan 0.79293915\n",
      " 0.7859215  0.79938161 0.79961117        nan        nan 0.80030241\n",
      " 0.8005323  0.7991516  0.79811586 0.79017748 0.79788558 0.7844254\n",
      " 0.79800065 0.79765543 0.79984152 0.79800072        nan 0.80041656\n",
      " 0.79604464        nan 0.78373627        nan 0.79938155 0.78304576\n",
      "        nan 0.79293967 0.80099154 0.79788558 0.78845268 0.79984165\n",
      " 0.80053163 0.80110727 0.79236318 0.79777057 0.79869103 0.79788571\n",
      "        nan 0.79903646 0.79834528 0.79972618 0.79052251 0.79961196\n",
      "        nan 0.79857629 0.79236357 0.78362087 0.79765509 0.80007173\n",
      " 0.80099266 0.79777043 0.79638993 0.80099233 0.79915146 0.79972664\n",
      " 0.77878938 0.79926528 0.79213342 0.78396622 0.79604511 0.79121355\n",
      "        nan 0.78316083        nan 0.80030188        nan 0.79685023\n",
      " 0.79972618 0.80041669 0.7982312  0.7858061  0.79201868 0.80064651\n",
      " 0.78845262 0.79029355 0.80133762 0.79754028 0.79915113 0.79938142\n",
      " 0.79086873 0.79938108 0.79719519        nan 0.79017675        nan\n",
      " 0.80030195 0.7680904  0.79995666        nan 0.79903685 0.78718719\n",
      " 0.79949662        nan 0.79615985 0.79811539 0.80168232 0.80007206\n",
      " 0.78810786 0.78983365 0.79788637 0.78373693 0.79616038 0.79938161\n",
      " 0.79800039 0.79109821        nan 0.80041649 0.80133696 0.79339839\n",
      " 0.79477961 0.78396616 0.7873022  0.789143          nan 0.79777037\n",
      "        nan 0.79949642        nan 0.79949642 0.77384308 0.80145243\n",
      " 0.79995619        nan 0.78971771 0.78638233 0.78523152        nan\n",
      " 0.79627473 0.79811619        nan 0.79040829 0.77821453 0.79293888\n",
      "        nan 0.79374487 0.79155904 0.79834594 0.79903619 0.80018667\n",
      " 0.79846042 0.79478014        nan 0.79903659        nan 0.78281627\n",
      "        nan 0.78638187 0.79984218 0.79351452 0.79880637 0.79282447\n",
      " 0.76452447 0.78500137 0.80179785 0.79834594 0.79224923 0.7680904\n",
      " 0.80133742 0.79834515 0.80076231 0.7991508  0.78845249 0.79926608\n",
      " 0.80053236        nan 0.79846088 0.80076211 0.78465647        nan\n",
      " 0.79972657 0.79742514 0.79167352        nan 0.80007167 0.79385981\n",
      "        nan 0.79374421 0.78086013 0.79754095 0.79972717 0.79339825\n",
      " 0.79857649 0.78661169 0.79846088 0.77384308 0.80122155 0.80076218\n",
      " 0.79592957 0.79535446 0.80110721 0.80053196 0.78281561        nan\n",
      " 0.79616038 0.78948829 0.79731007 0.7978861  0.8001872  0.80191247\n",
      "        nan 0.79328411 0.79627512 0.78580676 0.80007206        nan\n",
      "        nan 0.79880564 0.79811632        nan 0.79880637 0.79581529\n",
      "        nan        nan 0.79892138 0.79949669        nan 0.80053249\n",
      " 0.79857675 0.79926614 0.80076211 0.79420444        nan 0.79731093\n",
      "        nan 0.80041722 0.80179746 0.78212529 0.79305488 0.79995712\n",
      " 0.78235584 0.76820548 0.79719486        nan 0.78879784 0.79397442\n",
      " 0.79615998 0.79604464        nan        nan 0.79869183 0.79903692\n",
      " 0.79006327        nan 0.79938175 0.79719513        nan 0.78787771\n",
      " 0.78971665 0.80156737 0.78235465        nan 0.78431092 0.79972591\n",
      " 0.79224856 0.79823047 0.79397436 0.79972671 0.79500937        nan\n",
      " 0.79247918 0.79708025 0.78672676        nan 0.78580643 0.79984178\n",
      " 0.79857622 0.7919038  0.79017722        nan 0.79811566 0.80133729\n",
      " 0.80156744        nan 0.80030155 0.79869136 0.80076172 0.80076178\n",
      "        nan 0.78845275 0.7848855  0.79708045 0.78971665 0.7991516\n",
      " 0.79190394        nan 0.7978863         nan 0.78500176 0.79351465\n",
      "        nan        nan        nan 0.80007173 0.79846135 0.79708085\n",
      " 0.78155124 0.79616038 0.8000716  0.79880617 0.79662035 0.79270919\n",
      " 0.80110727        nan 0.78603684        nan 0.80041663 0.7855774\n",
      " 0.79903626 0.78580676        nan 0.79949642 0.80007206 0.80030181\n",
      " 0.78810759 0.79938161 0.79236351 0.78189554        nan 0.7827002\n",
      " 0.79788624        nan        nan        nan 0.79857583 0.79719513\n",
      "        nan        nan 0.79949642 0.7988065  0.7996111  0.79224923\n",
      " 0.80076198 0.78994846 0.80099233 0.80248777        nan 0.79903665\n",
      " 0.78396569 0.79604544 0.7988065  0.79926733        nan        nan\n",
      "        nan 0.79892145        nan 0.79857609 0.80145243        nan\n",
      " 0.79075385 0.79777083 0.79006333        nan 0.79961183        nan\n",
      " 0.78845222 0.79017748 0.79063824        nan 0.79351439 0.79823126\n",
      " 0.79708111        nan 0.7954702  0.80053124 0.77395716 0.77683397\n",
      " 0.77269319        nan 0.78799272        nan 0.79167352        nan\n",
      " 0.78258599 0.78994687        nan 0.79880584 0.79949689 0.77200288\n",
      " 0.79788531        nan 0.79431958 0.79857569 0.79984152        nan\n",
      " 0.78764756 0.79432024 0.79846095 0.80179752 0.79662068 0.79915173\n",
      " 0.792709   0.79109887 0.79040849 0.79869083        nan 0.79742587\n",
      " 0.80133729 0.78925741 0.7859217  0.79800105 0.80156717 0.79420431\n",
      "        nan 0.78879764 0.79224823 0.78672762 0.78695751        nan\n",
      " 0.79984165 0.79869136]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters CV:  {'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.5, 0.75],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "random_search_rf = RandomizedSearchCV(rf_model, param_grid_rf, n_iter=500, cv=5, scoring='accuracy', verbose=1, random_state=1)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params_rf = random_search_rf.best_params_\n",
    "print(\"Best Parameters CV: \", best_params_rf)\n",
    "\n",
    "# Create the Random Forest model with best parameters\n",
    "model_rf = RandomForestClassifier(**best_params_rf, random_state=1)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Prepare submission\n",
    "test_predictions_rf = pd.DataFrame({\n",
    "    'PassengerId': test_passenger_ids,\n",
    "    'Transported': y_test_pred_rf\n",
    "})\n",
    "\n",
    "test_predictions_rf['Transported'] = test_predictions_rf['Transported'].astype(bool)\n",
    "\n",
    "# Export to CSV\n",
    "test_predictions_rf.to_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Test\\\\Submission - Random Forest.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK FIRE RETRAIN USING BEST PARAMETERS\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train = pd.read_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Process\\\\CombinedTrain.csv\")\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Process\\\\CombinedTest.csv\")\n",
    "\n",
    "# Separate ID before training\n",
    "train_passenger_ids = train['PassengerId']\n",
    "test_passenger_ids = test['PassengerId']\n",
    "\n",
    "# Prepare data\n",
    "X_train = train.drop(['Transported', 'PassengerId'], axis=1)\n",
    "y_train = train['Transported'].astype('int')  # Convert True/False to 1/0\n",
    "X_test = test.drop('PassengerId', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Create the Random Forest model with best parameters\n",
    "best_params_rf = {'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'bootstrap': True}\n",
    "model_rf = RandomForestClassifier(**best_params_rf, random_state=1)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Prepare submission\n",
    "test_predictions_rf = pd.DataFrame({\n",
    "    'PassengerId': test_passenger_ids,\n",
    "    'Transported': y_test_pred_rf\n",
    "})\n",
    "test_predictions_rf['Transported'] = test_predictions_rf['Transported'].astype(bool)\n",
    "\n",
    "# Export to CSV\n",
    "test_predictions_rf.to_csv(\"C:\\\\Users\\\\joshn\\\\Documents\\\\Coding\\\\Spaceship Titanic\\\\Stacking\\\\Test\\\\Submission - Random Forest.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
